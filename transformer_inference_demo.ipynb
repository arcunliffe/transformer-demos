{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library dependencies\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text encoding:\n",
    "### Convert strings to an array of numbers that can be fed as input to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a tokenizer - used to encode the text\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: tokenization - split text into \"words\"\n",
    "text = \"I would like to go fishing.\"\n",
    "print(tokenizer.tokenize(text))\n",
    "# text = \"I would like to go to the PyMNtos meet-up.\"\n",
    "# print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: convert tokens to numbers\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))\n",
    "# print(len(tokens))\n",
    "# print(len(tokenizer.convert_tokens_to_ids(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Demo\n",
    "## Using a pre-trained transformer model and the Hugging Face transformers library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a pre-trained [tokenizer and model for sentiment analysis](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) from the [Hugging Face model repository](https://huggingface.co/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_MODEL_NAME = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(SENTIMENT_MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(SENTIMENT_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference and examine the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I am so happy that I joined the PyMNtos group.\"\n",
    "# text = \"Really disappointed in the PyMNTos talk that Alex Cunliffe gave - so boring!\"\n",
    "# text = \"When is the next meet-up?\"\n",
    "\n",
    "tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    out = model(**tokenized_text)\n",
    "print(\"out:\", out.logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply softmax activation\n",
    " - commonly used for multi-class classification\n",
    " - standardizes outputs to numbers between 0 and 1\n",
    " - sum(softmax outputs) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_result = torch.softmax(out.logits[0], dim=0)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Softmax result:\", softmax_result)\n",
    "print(\"Predicted sentiment:\", [\"Negative\", \"Neutral\", \"Positive\"][np.argmax(softmax_result.numpy())])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1decd3ced8173a0691ce1c645475fb900d85e053988a4a847c2b5e2de6b71515"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
